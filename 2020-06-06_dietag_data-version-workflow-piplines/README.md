# Workflow, piplines and version controlling big datasets

*An overview over the landscape of Git extensions to cope with large files*


In traditional software engineering binary files are typically small and very
static (test data) or easily reproducible (compiled binaries which are copied
to package servers by a CI server after each commit). Build systems are used to
start this process and skip steps automatically to safe processing time. When
working with data, things seem to be a bit different. Computation time can be
very large, you may want to sync and version control binary outputs. A quick
overview of Dataled, DVC, GIT-LFS and others.

- Kind: Talk (Presentation)
- Duration: 25
- at the [DIETAG 202-06-06](https://gitlab.com/caichinger/diedag-dietag_20200606/) (no public access)
