A desperate guide to data analysis workflow improvements
========================================================

**A list of ideas, tips and best practices on how to make your data analysis project more use-able -
for your self and others.**


Presentation at the event event of the Data Science @ BOKU initiative with the topic [Reproducible
Data
Analysis](https://boku.ac.at/nwnr/stat/data-science-boku/data-science-events/reproducible-data-analysis-29-feb-2024) on
February 29th 2024.


Slides
------

- [Public version of Google Slides](https://docs.google.com/presentation/d/e/2PACX-1vR0qILndW0r-GAd2XBAFO9E772Skn4UWMf7F9INzN2_aWSXjGH_hl-8Y0IahQ629r4YMFfSS_c46TFR/pub?start=false&loop=false&delayms=3000)
- [Exported PDF file](2024-02-29_boku_desperate-workflow-guidelines.pdf)


Abstract
--------

We will discuss the differences and the overlap between software engineering and data science with
regards to workflow issues and tools available. Many of these tools have been designed for typical
uses cases found in software projects and are not perfectly applicable for data analysis. We list
ideas and tips on how to make your data analysis project more use-able - for your self and others.
This will involve conventions and best practices on how to publish and structure both your code and
your data - including your results. But we will also have quick look on tools to organize a
computation pipeline, handle a huge pile of parameters and how to deal with versioning of data.
